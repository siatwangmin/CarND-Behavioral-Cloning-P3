{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Behavioral Cloning** \n",
    "\n",
    "---\n",
    "\n",
    "**Behavioral Cloning Project**\n",
    "\n",
    "The goals of this project are the following:\n",
    "* Use the simulator to collect data of good driving behavior\n",
    "* Build, a convolution neural network in Keras that predicts steering angles from images\n",
    "* Train and validate the model with a training and validation set\n",
    "* Test that the model successfully drives around track one without leaving the road\n",
    "* Summarize the results with a written report\n",
    "\n",
    "## Code and Usage\n",
    "\n",
    "My project includes the following files:\n",
    "* model.py containing the script to create and train the model\n",
    "* drive.py for driving the car in autonomous mode\n",
    "* model.h5 containing a trained convolution neural network \n",
    "* README.md summarizing the results**\n",
    "\n",
    "#### 2. Submission includes functional code\n",
    "Using the Udacity provided simulator and my drive.py file, the car can be driven autonomously around the track by executing \n",
    "```sh\n",
    "python drive.py model.h5\n",
    "```\n",
    "\n",
    "#### 3. Submission code is usable and readable\n",
    "\n",
    "The model.py file contains the code for training and saving the convolution neural network. The file shows the pipeline I used for training and validating the model.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Steps\n",
    "**Here I describe  my implementation of the project. **\n",
    "\n",
    "### Model Architecture and Training Strategy\n",
    "\n",
    "#### 1. Model architecture design\n",
    "\n",
    "My model consists of 5 a convolution neural network layers (model.py lines 24-48)，and 5 fully connnected layers(model.py lines 53-66). the data is normalized in the model using a Keras lambda layer (code line 22), and Max pooling is add after each convolution layers. To introduce nonlinearity , the model use RELU activation.  \n",
    "\n",
    "\n",
    "#### 2. Methods to reduce overfitting in the model\n",
    "\n",
    "The model was trained and validated on different data sets to ensure that the model was not overfitting (code line 73-74). and each epoch the training data num is 20032(75.8%) and the validation data num is 6400(24.2%). The model was tested by running it through the simulator and ensuring that the vehicle could stay on the track.\n",
    "\n",
    "#### 3. Model parameter tuning\n",
    "\n",
    "The model used an adam optimizer, the learning rate was set 0.0001 (model.py line 15).\n",
    "\n",
    "#### 4. Training data generation\n",
    "\n",
    "Training data was chosen to keep the vehicle driving on the road. I used a combination of clockwise lane driving and counter-clockwise driving, some random data generations were added to get more data\n",
    "\n",
    "For details about how I created the training data, see the next section. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Model Architecture and Training Strategy\n",
    "\n",
    "#### 1. Solution Design Approach\n",
    "First I have tried LeNet since it is a good start. The car is able to make the first turn but it is get off befor the first bridge, I modified LeNet into deeper network and add two more 5×5×64 convolution layers, and it can get through the bridge, but went off the road after the bridge. The LeNet is too shallow and its repretation abilities is limited, so I try from  the NVIDIA model, which has been used by NVIDIA for the end-to-end self driving test. As such, it is well suited for the project.\n",
    "\n",
    "In order to gauge how well the model was working, I split my image and steering angle data into a training and validation set.To speed up the training process, I crop the image rows of the trees, sky and and water, modified the image input to 64×64×3, and normalize the image data. I found that my first model had a low mean squared error on the training set but a high mean squared error on the validation set. This implied that the model was overfitting. To combat the overfitting, I add random adversity to trainning data, randomly shear, flip, rotate and augament the image.At the end of the process, the vehicle is able to drive autonomously around the track without leaving the road.\n",
    "\n",
    "[//]: # (Image References)\n",
    "\n",
    "[image1]: ./examples/conv_architecture.png \"Model Visualization\"\n",
    "\n",
    "\n",
    "#### 2. Final Model Architecture\n",
    "\n",
    "The final model architecture (model.py lines 18-68) consisted of 5 a convolution neural network layers and 5 fully connected layers.Here is a visualization of the architecture \n",
    "\n",
    "![alt text][image1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[image2]: ./examples/counter-clockwise.jpg \"Counter-Clockwise Image\"\n",
    "[image3]: ./examples/clockwise.jpg \"Clockwise Image\"\n",
    "\n",
    "#### 3. Creation of the Training Set & Training Process\n",
    "\n",
    "To capture good driving behavior, I first recorded two laps on track one using counter-clockwise lane driving. Here is an example image of center lane driving:\n",
    "\n",
    "![alt text][image2]\n",
    "\n",
    "I then recorded the vehicle two laps on track using clockwise lane driving as below:\n",
    "\n",
    "![alt text][image3]\n",
    "\n",
    "[image4]: ./examples/sheared.png \"sheared Image\"\n",
    "[image5]: ./examples/cropped.png \"Cropped Image\"\n",
    "[image6]: ./examples/flipped.png \"Flipped Image\"\n",
    "[image7]: ./examples/resized.png \"Resized Image\"\n",
    "[image8]: ./examples/jungle.jpg \"Jungle Image\"\n",
    "\n",
    "To augment the data set, I also randomly sheared, randomly croped and randomly flipped images,So I can get endless data. For example, here is an image that has then been sheared:\n",
    "![alt text][image4]\n",
    "\n",
    "the sky and trees are not releate to the lane keeping, to speed up the training, we cropped the image. 35% of the original image from the top and 10% image from the bottom are removed. here is an image that has then been cropped:\n",
    "![alt text][image5]\n",
    "\n",
    "To make the model not bias to the driving orientation, we flipped the image and the measurement. there are 0.5 probability that a image is flipped. here is an image that has then been flipped:\n",
    "![alt text][image6]\n",
    "\n",
    "\n",
    "To speed up the training process, smaller data will be a good option, so image is resize into 64×64×3. here is an image that has then been resized:\n",
    "![alt text][image7]\n",
    "\n",
    "To make the model make self-driving in the jungle lane , I also get training data from the jungle lane and make same augmentation to it, Since I drive slowly in the jungle lane, it can only drive at 15km/h speed. here is an image from jungle:\n",
    "![alt text][image8]\n",
    "\n",
    "Finally, In each epcho, I get randomly 20032 images data and 6400 images data. I used this training data for training the model. The validation set helped determine if the model was over or under fitting. \n",
    "Finally, we tried epochs  such as 5, 10, 25, 30 and 100. However, **30** works well on both training and validation tracks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
